# =============================================================================
# SEMANTIC CLASSIFIER - ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to version control (it's in .gitignore)

# =============================================================================
# LLM API KEYS
# =============================================================================

# OpenAI Configuration (REQUIRED)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Configuration (OPTIONAL - for direct Claude API access)
# Get your API key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# =============================================================================
# AWS BEDROCK CONFIGURATION (OPTIONAL)
# =============================================================================
# Required for using Claude models via AWS Bedrock
# Get credentials from AWS IAM Console

# AWS Credentials
AWS_ACCESS_KEY_ID=your_aws_access_key_id_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key_here
AWS_REGION_NAME=us-east-1

# Optional: AWS Bedrock Inference Profile ARNs
# These are region-specific endpoints for Claude models
# AWS_BEDROCK_OPUS_PROFILE_ARN=arn:aws:bedrock:us-east-1:123456789012:inference-profile/us.anthropic.claude-opus-4-5-20251101-v1:0
# AWS_BEDROCK_SONNET_PROFILE_ARN=arn:aws:bedrock:us-east-1:123456789012:inference-profile/us.anthropic.claude-sonnet-4-5-20250929-v1:0

# Alternative: AWS Bearer Token (if using token-based authentication)
# AWS_BEARER_TOKEN_BEDROCK=your_bearer_token_here

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================

# Default LLM Model
# Options: gpt-5.2-2025-12-11, gpt-5.1, gpt-4.1, claude-opus-4-5-20251101, etc.
LLM_MODEL=gpt-5.2-2025-12-11

# LLM Temperature (0.0 = deterministic, 2.0 = very creative)
# Recommended: 0.1 for classification tasks
LLM_TEMPERATURE=0.1

# Maximum tokens for LLM responses
LLM_MAX_TOKENS=2000

# =============================================================================
# DATA PROCESSING CONFIGURATION
# =============================================================================

# Maximum rows to show in data preview
MAX_PREVIEW_ROWS=100

# Sample size for category discovery
SAMPLE_SIZE=50

# Maximum tokens to use when sampling data
MAX_TOKENS_FOR_SAMPLING=8000

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# PostgreSQL Connection URL
# Format: postgresql://username:password@host:port/database_name
# Example: postgresql://postgres:mypassword@localhost:5432/semantic_classifier
DATABASE_URL=postgresql://user:password@host:5432/database_name

# Database Connection Pool Settings
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=10
DB_POOL_TIMEOUT=30
DB_POOL_RECYCLE=3600
DB_ECHO=False

# =============================================================================
# SUPABASE CONFIGURATION
# =============================================================================
# Get these from your Supabase project settings:
# https://app.supabase.com/project/_/settings/api

# Supabase Project URL
SUPABASE_URL=https://your-project-id.supabase.co

# Supabase Anon/Public Key (for client-side operations)
Supabase_api_key=your_supabase_anon_key_here

# Supabase Service Role Key (for server-side operations - keep secret!)
Supabase_secret_key=your_supabase_service_role_key_here

# =============================================================================
# SUPABASE STORAGE CONFIGURATION
# =============================================================================

# Storage bucket name for file uploads (must exist in Supabase)
SUPABASE_BUCKET_NAME=uploads

# =============================================================================
# LOGGING CONFIGURATION (OPTIONAL)
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# LOG_LEVEL=INFO

# =============================================================================
# NOTES
# =============================================================================
#
# REQUIRED SERVICES:
# 1. OpenAI API account (for LLM access)
# 2. Supabase account (for database and file storage)
#
# OPTIONAL SERVICES:
# 3. Anthropic API account (for direct Claude access)
# 4. AWS Account with Bedrock access (for Claude via AWS)
#
# SETUP STEPS:
# 1. Copy this file to .env
# 2. Fill in your API keys and database credentials
# 3. Create a Supabase project and get DATABASE_URL
# 4. Create an "uploads" bucket in Supabase Storage
# 5. Run: alembic upgrade head (to initialize database)
# 6. Run: streamlit run app.py
#
# For detailed setup instructions, see: docs/README.md
# =============================================================================
